component 0,flag,username,timestamp
"{""headers"":[""title"",""abstract"",""authors"",""id"",""categories"",""update_date""],""data"":[[""Hybrid quantum-classical convolutional neural networks to improve\n  molecular protein binding affinity predictions"",""One of the main challenges in drug discovery is to find molecules that bind specifically and strongly to their target protein while having minimal binding to other proteins. By predicting binding affinity, it is possible to identify the most promising candidates from a large pool of potential compounds, reducing the number of compounds that need to be tested experimentally. Recently, deep learning methods have shown superior performance than traditional computational methods for making accurate predictions on large datasets. However, the complexity and time-consuming nature of these methods have limited their usage and development. Quantum machine learning is an emerging technology that has the potential to improve many classical machine learning algorithms. In this work we present a hybrid quantum-classical convolutional neural network, which is able to reduce by 20% the complexity of the classical network while maintaining optimal performance in the predictions. Additionally, it results in a significant time savings of up to 40% in the training process, which means a meaningful speed up of the drug discovery process."",""L. Domingo and M. Djukic and C. Johnson and F. Borondo"",""2301.06331"",""quant-ph cs.LG q-bio.BM"",""2023-01-19""],[""Deep Learning Methods for Small Molecule Drug Discovery: A Survey"",""With the development of computer-assisted techniques, research communities including biochemistry and deep learning have been devoted into the drug discovery field for over a decade. Various applications of deep learning have drawn great attention in drug discovery, such as molecule generation, molecular property prediction, retrosynthesis prediction, and reaction prediction. While most existing surveys only focus on one of the applications, limiting the view of researchers in the community. In this paper, we present a comprehensive review on the aforementioned four aspects, and discuss the relationships among different applications. The latest literature and classical benchmarks are presented for better understanding the development of variety of approaches.   We commence by summarizing the molecule representation format in these works, followed by an introduction of recent proposed approaches for each of the four tasks. Furthermore, we review a variety of commonly used datasets and evaluation metrics and compare the performance of deep learning-based models. Finally, we conclude by identifying remaining challenges and discussing the future trend for deep learning methods in drug discovery."",""Wenhao Hu, Yingying Liu, Xuanyu Chen, Wenhao Chai, Hangyue Chen,\n  Hongwei Wang and Gaoang Wang"",""2303.00313"",""cs.LG q-bio.BM"",""2023-03-07""],[""RECOVER: sequential model optimization platform for combination drug\n  repurposing identifies novel synergistic compounds in vitro"",""For large libraries of small molecules, exhaustive combinatorial chemical screens become infeasible to perform when considering a range of disease models, assay conditions, and dose ranges. Deep learning models have achieved state of the art results in silico for the prediction of synergy scores. However, databases of drug combinations are biased towards synergistic agents and these results do not necessarily generalise out of distribution. We employ a sequential model optimization search utilising a deep learning model to quickly discover synergistic drug combinations active against a cancer cell line, requiring substantially less screening than an exhaustive evaluation. Our small scale wet lab experiments only account for evaluation of ~5% of the total search space. After only 3 rounds of ML-guided in vitro experimentation (including a calibration round), we find that the set of drug pairs queried is enriched for highly synergistic combinations; two additional rounds of ML-guided experiments were performed to ensure reproducibility of trends. Remarkably, we rediscover drug combinations later confirmed to be under study within clinical trials. Moreover, we find that drug embeddings generated using only structural information begin to reflect mechanisms of action. Prior in silico benchmarking suggests we can enrich search queries by a factor of ~5-10x for highly synergistic drug combinations by using sequential rounds of evaluation when compared to random selection, or by a factor of >3x when using a pretrained model selecting all drug combinations at a single time point."",""Paul Bertin, Jarrid Rector-Brooks, Deepak Sharma, Thomas Gaudelet,\n  Andrew Anighoro, Torsten Gross, Francisco Martinez-Pena, Eileen L. Tang,\n  Suraj M S, Cristian Regep, Jeremy Hayter, Maksym Korablyov, Nicholas\n  Valiante, Almer van der Sloot, Mike Tyers, Charles Roberts, Michael M.\n  Bronstein, Luke L. Lairson, Jake P. Taylor-King, and Yoshua Bengio"",""2202.04202"",""q-bio.QM cs.LG"",""2023-03-06""],[""AMFPMC -- An improved method of detecting multiple types of drug-drug\n  interactions using only known drug-drug interactions"",""Adverse drug interactions are largely preventable causes of medical accidents, which frequently result in physician and emergency room encounters. The detection of drug interactions in a lab, prior to a drug's use in medical practice, is essential, however it is costly and time-consuming. Machine learning techniques can provide an efficient and accurate means of predicting possible drug-drug interactions and combat the growing problem of adverse drug interactions. Most existing models for predicting interactions rely on the chemical properties of drugs. While such models can be accurate, the required properties are not always available."",""Bar Vered and Guy Shtar and Lior Rokach and Bracha Shapira"",""2302.03355"",""cs.LG"",""2023-02-08""],[""Pharmacoprint -- a combination of pharmacophore fingerprint and\n  artificial intelligence as a tool for computer-aided drug design"",""Structural fingerprints and pharmacophore modeling are methodologies that have been used for at least two decades in various fields of cheminformatics: from similarity searching to machine learning (ML). Advances in silico techniques consequently led to combining both these methodologies into a new approach known as pharmacophore fingerprint. Herein, we propose a high-resolution, pharmacophore fingerprint called Pharmacoprint that encodes the presence, types, and relationships between pharmacophore features of a molecule. Pharmacoprint was evaluated in classification experiments by using ML algorithms (logistic regression, support vector machines, linear support vector machines, and neural networks) and outperformed other popular molecular fingerprints (i.e., Estate, MACCS, PubChem, Substructure, Klekotha-Roth, CDK, Extended, and GraphOnly) and ChemAxon Pharmacophoric Features fingerprint. Pharmacoprint consisted of 39973 bits; several methods were applied for dimensionality reduction, and the best algorithm not only reduced the length of bit string but also improved the efficiency of ML tests. Further optimization allowed us to define the best parameter settings for using Pharmacoprint in discrimination tests and for maximizing statistical parameters. Finally, Pharmacoprint generated for 3D structures with defined hydrogens as input data was applied to neural networks with a supervised autoencoder for selecting the most important bits and allowed to maximize Matthews Correlation Coefficient up to 0.962. The results show the potential of Pharmacoprint as a new, perspective tool for computer-aided drug design."",""Dawid Warszycki, {\\L}ukasz Struski, Marek \\'Smieja, Rafa{\\l} Kafel,\n  Rafa{\\l} Kurczab"",""2110.01339"",""q-bio.QM cs.LG"",""2023-11-01""]],""metadata"":null}",,,2024-01-01 15:48:28.266656
"{""headers"":[""title"",""abstract"",""authors"",""id"",""categories"",""update_date""],""data"":[[""Improving CNN-base Stock Trading By Considering Data Heterogeneity and\n  Burst"",""In recent years, there have been quite a few attempts to apply intelligent techniques to financial trading, i.e., constructing automatic and intelligent trading framework based on historical stock price. Due to the unpredictable, uncertainty and volatile nature of financial market, researchers have also resorted to deep learning to construct the intelligent trading framework. In this paper, we propose to use CNN as the core functionality of such framework, because it is able to learn the spatial dependency (i.e., between rows and columns) of the input data. However, different with existing deep learning-based trading frameworks, we develop novel normalization process to prepare the stock data. In particular, we first empirically observe that the stock data is intrinsically heterogeneous and bursty, and then validate the heterogeneity and burst nature of stock data from a statistical perspective. Next, we design the data normalization method in a way such that the data heterogeneity is preserved and bursty events are suppressed. We verify out developed CNN-based trading framework plus our new normalization method on 29 stocks. Experiment results show that our approach can outperform other comparing approaches."",""Keer Yang, Guanqun Zhang, Chuan Bi, Qiang Guan, Hailu Xu, Shuai Xu"",""2303.09407"",""q-fin.ST cs.LG"",""2023-03-17""],[""A Novel Deep Reinforcement Learning Based Automated Stock Trading System\n  Using Cascaded LSTM Networks"",""More and more stock trading strategies are constructed using deep reinforcement learning (DRL) algorithms, but DRL methods originally widely used in the gaming community are not directly adaptable to financial data with low signal-to-noise ratios and unevenness, and thus suffer from performance shortcomings. In this paper, to capture the hidden information, we propose a DRL based stock trading system using cascaded LSTM, which first uses LSTM to extract the time-series features from stock daily data, and then the features extracted are fed to the agent for training, while the strategy functions in reinforcement learning also use another LSTM for training. Experiments in DJI in the US market and SSE50 in the Chinese stock market show that our model outperforms previous baseline models in terms of cumulative returns and Sharp ratio, and this advantage is more significant in the Chinese stock market, a merging market. It indicates that our proposed method is a promising way to build a automated stock trading system."",""Jie Zou, Jiashu Lou, Baohua Wang, Sixue Liu"",""2212.02721"",""q-fin.CP cs.AI q-fin.PM"",""2023-07-27""],[""Improved Stock Price Movement Classification Using News Articles Based\n  on Embeddings and Label Smoothing"",""Stock price movement prediction is a challenging and essential problem in finance. While it is well established in modern behavioral finance that the share prices of related stocks often move after the release of news via reactions and overreactions of investors, how to capture the relationships between price movements and news articles via quantitative models is an active area research; existing models have achieved success with variable degrees. In this paper, we propose to improve stock price movement classification using news articles by incorporating regularization and optimization techniques from deep learning. More specifically, we capture the dependencies between news articles and stocks through embeddings and bidirectional recurrent neural networks as in recent models. We further incorporate weight decay, batch normalization, dropout, and label smoothing to improve the generalization of the trained models. To handle high fluctuations of validation accuracy of batch normalization, we propose dual-phase training to realize the improvements reliably. Our experimental results on a commonly used dataset show significant improvements, achieving average accuracy of 80.7% on the test set, which is more than 10.0% absolute improvement over existing models. Our ablation studies show batch normalization and label smoothing are most effective, leading to 6.0% and 3.4% absolute improvement, respectively on average."",""Luis Villamil, Ryan Bausback, Shaeke Salman, Ting L. Liu, Conrad Horn,\n  Xiuwen Liu"",""2301.10458"",""cs.LG cs.AI cs.CL cs.NE"",""2023-01-26""],[""Quant 4.0: Engineering Quantitative Investment with Automated,\n  Explainable and Knowledge-driven Artificial Intelligence"",""Quantitative investment (``quant'') is an interdisciplinary field combining financial engineering, computer science, mathematics, statistics, etc. Quant has become one of the mainstream investment methodologies over the past decades, and has experienced three generations: Quant 1.0, trading by mathematical modeling to discover mis-priced assets in markets; Quant 2.0, shifting quant research pipeline from small ``strategy workshops'' to large ``alpha factories''; Quant 3.0, applying deep learning techniques to discover complex nonlinear pricing rules. Despite its advantage in prediction, deep learning relies on extremely large data volume and labor-intensive tuning of ``black-box'' neural network models. To address these limitations, in this paper, we introduce Quant 4.0 and provide an engineering perspective for next-generation quant. Quant 4.0 has three key differentiating components. First, automated AI changes quant pipeline from traditional hand-craft modeling to the state-of-the-art automated modeling, practicing the philosophy of ``algorithm produces algorithm, model builds model, and eventually AI creates AI''. Second, explainable AI develops new techniques to better understand and interpret investment decisions made by machine learning black-boxes, and explains complicated and hidden risk exposures. Third, knowledge-driven AI is a supplement to data-driven AI such as deep learning and it incorporates prior knowledge into modeling to improve investment decision, in particular for quantitative value investing. Moreover, we discuss how to build a system that practices the Quant 4.0 concept. Finally, we propose ten challenging research problems for quant technology, and discuss potential solutions, research directions, and future trends."",""Jian Guo, Saizhuo Wang, Lionel M. Ni, Heung-Yeung Shum"",""2301.04020"",""q-fin.CP cs.AI"",""2023-01-11""],[""A Novel Experts Advice Aggregation Framework Using Deep Reinforcement\n  Learning for Portfolio Management"",""Solving portfolio management problems using deep reinforcement learning has been getting much attention in finance for a few years. We have proposed a new method using experts signals and historical price data to feed into our reinforcement learning framework. Although experts signals have been used in previous works in the field of finance, as far as we know, it is the first time this method, in tandem with deep RL, is used to solve the financial portfolio management problem. Our proposed framework consists of a convolutional network for aggregating signals, another convolutional network for historical price data, and a vanilla network. We used the Proximal Policy Optimization algorithm as the agent to process the reward and take action in the environment. The results suggested that, on average, our framework could gain 90 percent of the profit earned by the best expert."",""MohammadAmin Fazli, Mahdi Lashkari, Hamed Taherkhani, Jafar Habibi"",""2212.14477"",""q-fin.CP cs.LG q-fin.PM"",""2023-01-02""]],""metadata"":null}",,,2024-01-01 15:48:29.682343
"{""headers"":[""title"",""abstract"",""authors"",""id"",""categories"",""update_date""],""data"":[[""Leukemia detection based on microscopic blood smear images using deep\n  learning"",""In this paper we discuss a new method for detecting leukemia in microscopic blood smear images using deep neural networks to diagnose leukemia early in blood. leukemia is considered one of the most dangerous mortality causes for a human being, the traditional process of diagnosis of leukemia in blood is complex, costly, and time-consuming, so patients could not receive medical treatment on time; Computer vision classification technique using deep learning can overcome the problems of traditional analysis of blood smears, our system for leukemia detection provides 97.3 % accuracy in classifying samples as cancerous or normal samples by taking a shot of blood smear and passing it as an input to the system that will check whether it contains cancer or not. In case of containing cancer cells, then the hematological expert passes the sample to a more complex device such as flow cytometry to generate complete information about the progress of cancer in the blood."",""Abdelmageed Ahmed, Alaa Nagy, Ahmed Kamal, and Daila Farghl"",""2301.03367"",""eess.IV cs.CV"",""2023-01-10""],[""A survey on automated detection and classification of acute leukemia and\n  WBCs in microscopic blood cells"",""Leukemia (blood cancer) is an unusual spread of White Blood Cells or Leukocytes (WBCs) in the bone marrow and blood. Pathologists can diagnose leukemia by looking at a person's blood sample under a microscope. They identify and categorize leukemia by counting various blood cells and morphological features. This technique is time-consuming for the prediction of leukemia. The pathologist's professional skills and experiences may be affecting this procedure, too. In computer vision, traditional machine learning and deep learning techniques are practical roadmaps that increase the accuracy and speed in diagnosing and classifying medical images such as microscopic blood cells. This paper provides a comprehensive analysis of the detection and classification of acute leukemia and WBCs in the microscopic blood cells. First, we have divided the previous works into six categories based on the output of the models. Then, we describe various steps of detection and classification of acute leukemia and WBCs, including Data Augmentation, Preprocessing, Segmentation, Feature Extraction, Feature Selection (Reduction), Classification, and focus on classification step in the methods. Finally, we divide automated detection and classification of acute leukemia and WBCs into three categories, including traditional, Deep Neural Network (DNN), and mixture (traditional and DNN) methods based on the type of classifier in the classification step and analyze them. The results of this study show that in the diagnosis and classification of acute leukemia and WBCs, the Support Vector Machine (SVM) classifier in traditional machine learning models and Convolutional Neural Network (CNN) classifier in deep learning models have widely employed. The performance metrics of the models that use these classifiers compared to the others model are higher."",""Mohammad Zolfaghari and Hedieh Sajedi"",""2303.03916"",""cs.CV"",""2023-03-13""],[""Automated risk classification of colon biopsies based on semantic\n  segmentation of histopathology images"",""Artificial Intelligence (AI) can potentially support histopathologists in the diagnosis of a broad spectrum of cancer types. In colorectal cancer (CRC), AI can alleviate the laborious task of characterization and reporting on resected biopsies, including polyps, the numbers of which are increasing as a result of CRC population screening programs, ongoing in many countries all around the globe. Here, we present an approach to address two major challenges in automated assessment of CRC histopathology whole-slide images. First, we present an AI-based method to segment multiple tissue compartments in the H\\&E-stained whole-slide image, which provides a different, more perceptible picture of tissue morphology and composition. We test and compare a panel of state-of-the-art loss functions available for segmentation models, and provide indications about their use in histopathology image segmentation, based on the analysis of a) a multi-centric cohort of CRC cases from five medical centers in the Netherlands and Germany, and b) two publicly available datasets on segmentation in CRC. Second, we use the best performing AI model as the basis for a computer-aided diagnosis system (CAD) that classifies colon biopsies into four main categories that are relevant pathologically. We report the performance of this system on an independent cohort of more than 1,000 patients. The results show the potential of such an AI-based system to assist pathologists in diagnosis of CRC in the context of population screening. We have made the segmentation model available for research use on https://grand-challenge.org/algorithms/colon-tissue-segmentation/."",""John-Melle Bokhorst, Iris D. Nagtegaal, Filippo Fraggetta, Simona\n  Vatrano, Wilma Mesker, Michael Vieth, Jeroen van der Laak, Francesco Ciompi"",""2109.07892"",""eess.IV cs.CV"",""2023-02-10""],[""Practical X-ray Gastric Cancer Screening Using Refined Stochastic Data\n  Augmentation and Hard Boundary Box Training"",""In gastric cancer screening, X-rays can be performed by radiographers, allowing them to see far more patients than endoscopy, which can only be performed by physicians. However, due to subsequent diagnostic difficulties, the sensitivity of gastric X-ray is only 85.5%, and little research has been done on automated diagnostic aids that directly target gastric cancer. This paper proposes a practical gastric cancer screening system for X-ray images taken under realistic clinical imaging conditions. Our system not only provides a diagnostic result for each image, but also provides an explanation for the result by displaying candidate cancer areas with bounding boxes. Training object detection models to do this was very expensive in terms of assigning supervised labels, and had the disadvantage of not being able to use negative (i.e., non-cancer) data for training. Our proposal consists of two novel techniques: (1) refined stochastic gastric image augmentation (R-sGAIA) and (2) hard boundary box training (HBBT). The R-sGAIA probabilistically highlights the gastric folds in the X-ray image based on medical knowledge, thus increasing the detection efficiency of gastric cancer. The HBBT is a new, efficient, and versatile training method that can reduce the number of false positive detections by actively using negative samples. The results showed that the proposed R-sGAIA and HBBT significantly improved the F1 score by 5.9% compared to the baseline EfficientDet-D7 + RandAugment (F1: 57.8%, recall: 90.2%, precision: 42.5%). This score is higher than the physician's cancer detection rate, indicating that at least 2 out of 5 areas detected are cancerous, confirming the utility of gastric cancer screening."",""Hideaki Okamoto, Takakiyo Nomura, Kazuhito Nabeshima, Jun Hashimoto,\n  Hitoshi Iyatomi"",""2108.08158"",""eess.IV cs.CV"",""2023-03-24""],[""Breast Cancer Classification using Deep Learned Features Boosted with\n  Handcrafted Features"",""Breast cancer is one of the leading causes of death among women across the globe. It is difficult to treat if detected at advanced stages, however, early detection can significantly increase chances of survival and improves lives of millions of women. Given the widespread prevalence of breast cancer, it is of utmost importance for the research community to come up with the framework for early detection, classification and diagnosis. Artificial intelligence research community in coordination with medical practitioners are developing such frameworks to automate the task of detection. With the surge in research activities coupled with availability of large datasets and enhanced computational powers, it expected that AI framework results will help even more clinicians in making correct predictions. In this article, a novel framework for classification of breast cancer using mammograms is proposed. The proposed framework combines robust features extracted from novel Convolutional Neural Network (CNN) features with handcrafted features including HOG (Histogram of Oriented Gradients) and LBP (Local Binary Pattern). The obtained results on CBIS-DDSM dataset exceed state of the art."",""Unaiza Sajid, Rizwan Ahmed Khan, Shahid Munir Shah, Sheeraz Arif"",""2206.12815"",""eess.IV cs.CV cs.LG"",""2023-08-17""]],""metadata"":null}",,,2024-01-01 15:48:30.805046
